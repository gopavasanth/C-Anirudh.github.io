[ { "title": "How to prepare for Campus Placements?", "url": "/C-Anirudh.github.io/posts/how-to-prepare-for-campus-placements/", "categories": "Other", "tags": "placement-preparation, experience", "date": "2021-07-16 15:00:00 +0530", "snippet": " This is written from my experience of appearing for campus placements. The blog post is a general guide and NOT written considering a specific company. The resources and the preparation method I used worked for me, however it might not be the same for you. Read through, consider the positives, and take the approach that works best for you! So lets get right to it!‚öôÔ∏è General Flow of a Company‚Äôs Selection ProcessThe number and type of rounds vary from company to company. Online Round(s) 1 or 2 online rounds MCQ questions can be: aptitude, reasoning, verbals, and other cognitive skills theoretical knowledge of SDLC, OOPs, DBMS, networks, and OS find the output questions based on pseudocode/C/C++/Java Group Discussion Tests communication skills and logical/abstract thinking Technical Interview Resume based questions Coding questions Theory questions &amp;amp; other role based questions Managerial Interview Interview by Managers or higher Test technical ability and team fit HR Interview About understanding the candidate and whether they are the right fit for the job ‚ùì What to Prepare Technical Other Predict the output questions (pseudocode/C/C++/Java) Aptitude, reasoning, verbals, and other cognitive skills Coding Have a well prepared Resume OOPs Prepare a solid Self Introduction DBMS, Networks, OS Prepare for Behavioural Questions SDLC Research about the company before going for an interview (Cannot stress this enough!) System Design Prepare a few questions to ask your interviewer at the end of the interview üìö Resourcesüß© Aptitude, Reasoning and VerbalsThere are various resources available online from where you can get questions and practice, Google!Practice commonly asked question patterns, this will enable you to solve faster ‚ö° during the actual exam which is important given that you have to solve many questions in a short amount of time.Important Topics in Aptitude Time and Work (Questions like how many men and women are required to complete the task, time taken to fill a tank by x pipes, etc) Number Theory Profit and Loss Ratio and Proportion (Questions like what will be the ratio of water and milk, if x litres of water is added, etc) Percentages Averageüë®‚Äçüíª CodingMost companies support Java, C++ and python in their online IDEs. The language requirement may vary based on the role.I mostly used Raj Vikramaditya‚Äôs SDE sheet to practice a wide variety of commonly asked questions. Even though you may not get the same exact question, solving these questions will help you plan your approach and solve similar questions easily. Go ahead and watch his YouTube video before jumping into the sheet.I also used to see company specific previously asked questions on GFG (https://practice.geeksforgeeks.org/explore/?page=1) before heading for the online round/interview.An excellent resource to practice dynamic programming: https://leetcode.com/discuss/general-discussion/458695/dynamic-programming-patterns/LeetCode and GFG are your friends!üìñ Theory SubjectsOOPsObject Oriented Programming by Prof. Swaminathan J : I would recommend everyone to go through it, if you are new to OOPs or want to review the fundamentals.Apart from these I went through various websites and read through commonly asked OOPs questions: https://www.edureka.co/blog/interview-questions/oops-interview-questions/ https://career.guru99.com/top-50-oops-interview-questions/ Differences between Procedural and Object Oriented Programming - GeeksforGeeks And a few other questions that I googled on my ownNote: I wouldn‚Äôt vouch for the answers provided on these websites. I would advice you to look at the question and search for an appropriate answer on your own.OS, DBMS, NetworksCommonly asked questions can be found here: https://www.geeksforgeeks.org/most-asked-computer-science-subjects-interview-questions-in-amazon-microsoft-flipkart/You don‚Äôt need to know each and every thing in these subjects. The commonly asked questions above provide you an idea of the topics that interviewers generally focus on. Concentrate on these topics, and prepare well either through your college notes (if you have one xD), or you can google and learn about them.If you have a lot of time to spare and understand Hindi, you can go through videos on these topics by Knowledge Gate.I practiced SQL from HackerRank, and solved almost all of the questions. Focus on aggregate functions, WHERE, GROUP BY, CASE, and joins.SDLCKnow about the various stages of Software Development Life Cycle and fundamental Agile Terminology.System DesignHave an idea on how to design a software end to end.Know how to draw UML diagrams (Google or watch a couple of YouTube videos about it).üë• Behavioural Questions/HR InterviewThis HR interview Guide explains the intent behind several commonly asked HR/behavioural questions and the best route we can take to answer the question. Remember to use the S-T-A-R approach." }, { "title": "Oracle Interview Experience", "url": "/C-Anirudh.github.io/posts/oracle-interview-experience/", "categories": "Other, Interview Experience", "tags": "oracle, interview-experience", "date": "2020-08-28 22:00:00 +0530", "snippet": "Oracle GBU campus placement drive | Virtual processRound 1Round 1 was an online MCQ round consisting of aptitude, verbals, reasoning, and technical questions. The round was divided into many sections with a separate time frame for each section. The total time, including all sections, was 107 minutes.Round 2 (Coding Round)Round 2 was an online coding round, in which we were given two coding questions to solve within 60 minutes: Graph m coloring problem (A slightly modified version of the original question) Print a string in zig-zag format (Similar question: https://www.geeksforgeeks.org/print-concatenation-of-zig-zag-string-form-in-n-rows/)Round 3 (Interview Round)The interviews were held over Zoom and consisted of the following rounds: Two Technical Interviews (about 1 hour each) One HR Interview (about 30 mins)Some of the Interview questionsBoth the technical interviewers took 2 minutes to read my resume and then asked questions based on it. Introduce yourself (2 times in both tech rounds) Rate yourself in the following: C++ Data Structures SQL OOPs/Java questions What is OOPs? What are the main concepts in OOPs? (abstraction, encapsulation, inheritance, polymorphism with real world examples) What is an example of runtime polymorphism? (function overriding) What is function overriding? What is function overloading? Difference between the two. He asked me syntax to inherit class in C++, the extends keyword is in Java. What is the difference between C++ and Java? What is JDK, JRE, JVM ? What is constructor? What is destructor? Why is return type of main void in Java? Return type of main in C++? He asked me output of following: class Test { public static void main(String[] args) { System.out.println(10 + 20 + &quot;TestCode&quot;); System.out.println(&quot;TestCode&quot; + 10 + 20); System.out.println(10 * 20 + &quot;TestCode&quot;); System.out.println(&quot;TestCode&quot; + 20*10); }} DBMS questions Query to find the maximum salary from employee table? (ans: SELECT MAX(salary) FROM Employee) What is primary key? What is foreign key? What is SQL? Difference between TRUNCATE and DELETE command? What is transaction? I was also asked about the life cycle of a transaction (partially committed, committed, ROLLBACK). Other technical questions I was asked to code the following question in Round 1: https://www.geeksforgeeks.org/add-two-numbers-without-using-arithmetic-operators/ I was asked to explain bubble sort in both tech rounds (asked to write pseudo code in second tech round) I was asked to explain and write pseudo code for binary search. He gave me a binary tree structure and asked all three traversal: postorder, preorder &amp;amp; inorder. He asked if given preorder traversal, can I tell postorder traversal? What is virtual table? What is MVC architecture? Resume based questions I was asked to explain each of my projects. Some questions mentioned above were also from resume. Other questions In round 2 I was asked this puzzle question: https://math.stackexchange.com/questions/1143132/is-there-a-size-of-rectangle-that-retains-its-ratio-when-its-folded-in-half In round 2 I was asked this aptitude question: Distance between A and B is 100 kms. One person starts from city A at 50 kmph and another starts from B at 40 kmph. At what point will they meet? Final result: Selected You can also find my experience penned down in GFG. https://www.geeksforgeeks.org/oracle-gbu-interview-experience-campus-placement-drive-2020-virtual-process/." }, { "title": "Notes - TCP Congestion Control", "url": "/C-Anirudh.github.io/posts/notes-tcp-congestion-control/", "categories": "Academic Notes, Computer Networks", "tags": "tcp, notes", "date": "2020-07-02 11:41:00 +0530", "snippet": " The following notes have been made with reference to the book Computer Networking A Top Down Approach by Kurose and Ross. Content has been quoted from the book. All credits to the author. TCP provides a reliable transport service between two processes running on different hosts. Another key component of TCP is its congestion-control mechanism. TCP must use end-to-end congestion control rather than network-assisted congestion control, since the IP layer provides no explicit feedback to the end systems regarding network congestion. The approach taken by TCP is to have each sender limit the rate at which it sends traffic into its connection as a function of perceived network congestion. If a TCP sender perceives that there is little congestion on the path between itself and the destination, then the TCP sender increases its send rate; if the sender perceives that there is congestion along the path, then the sender reduces its send rate. But this approach raises three questions. First, how does a TCP sender limit the rate at which it sends traffic into its connection? A TCP connection consists of a receive buffer, a send buffer, and several variables (LastByteRead, rwnd, etc). The TCP congestion-control mechanism operating at the sender keeps track of an additional variable, the congestion window. Congestion Window (cwnd) is a TCP state variable that limits the amount of data the TCP can send into the network before receiving an ACK. The Receiver Window (rwnd) is a variable that advertises the amount of data that the destination side can receive. Together, the two variables are used to regulate data flow in TCP connections, minimize congestion, and improve network performance. Specifically, the amount of unacknowledged data at a sender may not exceed the minimum of cwnd and rwnd (receiver window), that is : LastByteSent - LastByteAcked &amp;lt;= min{cwnd, rwnd} Assumptions made henceforth: The TCP receive buffer is so large that the receive-window constraint can be ignored; thus, the amount of unacknowledged data at the sender is solely limited by cwnd. We will also assume that the sender always has data to send, i.e., that all segments in the congestion window are sent. The constraint above limits the amount of unacknowledged data at the sender and therefore indirectly limits the sender‚Äôs send rate. At the beginning of every RTT, the constraint permits the sender to send cwnd bytes of data into the connection; at the end of the RTT the sender receives acknowledgments for the data. Thus the sender‚Äôs send rate is roughly cwnd/RTT bytes/sec. By adjusting the value of cwnd, the sender can therefore adjust the rate at which it sends data into its connection. Second, how does a TCP sender perceive that there is congestion on the path between itself and the destination? Let us define a ‚Äúloss event‚Äù at a TCP sender as the occurrence of either a timeout or the receipt of three duplicate ACKs from the receiver. When there is excessive congestion, then one (or more) router buffers along the path overflows, causing a datagram (containing a TCP segment) to be dropped. The dropped datagram, in turn, results in a loss event at the sender‚Äîeither a timeout or the receipt of three duplicate ACKs‚Äîwhich is taken by the sender to be an indication of congestion on the sender-to-receiver path. When the network is congestion-free, that is, when a loss event doesn‚Äôt occur. In this case, acknowledgments for previously unacknowledged segments will be received at the TCP sender. As we‚Äôll see, TCP will take the arrival of these acknowledgments as an indication that all is well‚Äîthat segments being transmitted into the network are being successfully delivered to the destination‚Äîand will use acknowledgments to increase its congestion window size (and hence its transmission rate). Note that if acknowledgments arrive at a relatively slow rate, then the congestion window will be increased at a relatively slow rate. On the other hand, if acknowledgments arrive at a high rate, then the congestion window will be increased more quickly. Because TCP uses acknowledgments to trigger (or clock) its increase in congestion window size, TCP is said to be self-clocking. Third, what algorithm should the sender use to change its send rate as a function of perceived end-to-end congestion? How then do the TCP senders determine their sending rates such that they don‚Äôt congest the network but at the same time make use of all the available bandwidth? Are TCP senders explicitly coordinated, or is there a distributed approach in which the TCP senders can set their sending rates based only on local information? TCP answers these questions using the following guiding principles: A lost segment implies congestion, and hence, the TCP sender‚Äôs rate should be decreased when a segment is lost. A timeout event or the receipt of four acknowledgments for a given segment (one original ACK and then three duplicate ACKs) is interpreted as an implicit ‚Äúloss event‚Äù indication of the segment following the quadruply ACKed segment, triggering a retransmission of the lost segment. From a congestion control standpoint, the question is how the TCP sender should decrease its congestion window size, and hence its sending rate, in response to this inferred loss event. An acknowledged segment indicates that the network is delivering the sender‚Äôs segments to the receiver, and hence, the sender‚Äôs rate can be increased when an ACK arrives for a previously unacknowledged segment. Bandwidth probing. Given ACKs indicating a congestion-free source-to-destination path and loss events indicating a congested path, TCP‚Äôs strategy for adjusting its transmission rate is to increase its rate in response to arriving ACKs until a loss event occurs, at which point, the transmission rate is decreased. The TCP sender thus increases its transmission rate to probe for the rate that at which congestion onset begins, backs off from that rate, and then to begins probing again to see if the congestion onset rate has changed. Note that there is no explicit signaling of congestion state by the network‚ÄîACKs and loss events serve as implicit signals‚Äîand that each TCP sender acts on local information asynchronously from other TCP senders. TCP congestion-control algorithm The algorithm has three major components: (1) slow start, (2) congestion avoidance, and (3) fast recovery. Slow start and congestion avoidance are mandatory components of TCP, differing in how they increase the size of cwnd in response to received ACKs. Slow start increases the size of cwnd more rapidly (despite its name!) than congestion avoidance. Fast recovery is recommended, but not required, for TCP senders.Slow Start When a TCP connection begins, the value of cwnd is typically initialized to a small value of 1 MSS (Maximum Segment Size), resulting in an initial sending rate of roughly MSS/RTT. Since the available bandwidth to the TCP sender may be much larger than MSS/RTT, the TCP sender would like tofind the amount of available bandwidth quickly. Thus, in the slow-start state, the value of cwnd begins at 1 MSS and increases by 1 MSS every time a transmitted segment is first acknowledged. This process results in a doubling of the sending rate every RTT. Thus, the TCP send rate starts slow but grows exponentially during the slow start phase. But when should this exponential growth end? Slow start provides several answers to this question. First, if there is a loss event (i.e., congestion) indicated by a timeout, the TCP sender sets the value of cwnd to 1 and begins the slow start process anew. It also sets the value of a second state variable, ssthresh (shorthand for ‚Äúslow start threshold‚Äù) to cwnd/2 ‚Äî half of the value of the congestion window value when congestion was detected. The second way in which slow start may end is directly tied to the value of ssthresh. Since ssthresh is half the value of cwnd when congestion was last detected, it might be a bit reckless to keep doubling cwnd when it reaches or surpasses the value of ssthresh. Thus, when the value of cwnd equals ssthresh, slow start ends and TCP transitions into congestion avoidance mode. TCP increases cwnd more cautiously when in congestion-avoidance mode. The final way in which slow start can end is if three duplicate ACKs are detected, in which case TCP performs a fast retransmit and enters the fast recovery state. Congestion Avoidance On entry to the congestion-avoidance state, the value of cwnd is approximately half its value when congestion was last encountered. Thus, rather than doubling the value of cwnd every RTT, TCP adopts a more conservative approach and increases the value of cwnd by just a single MSS every RTT. This can be accomplished in several ways. A common approach is for the TCP sender to increase cwnd by MSS bytes (MSS/cwnd) whenever a new acknowledgment arrives. For example, if MSS is 1,460 bytes and cwnd is 14,600 bytes, then 10 segments are being sent within an RTT. Each arriving ACK (assuming one ACK per segment) increases the congestion window size by 1/10 MSS, and thus, the value of the congestion window will have increased by one MSS after ACKs when all 10 segments have been received. But when should congestion avoidance‚Äôs linear increase (of 1 MSS per RTT) end? TCP‚Äôs congestion-avoidance algorithm behaves the same when a timeout occurs. As in the case of slow start: The value of cwnd is set to 1 MSS, and thevalue of ssthresh is updated to half the value of cwnd when the loss event occurred. Recall, however, that a loss event also can be triggered by a triple duplicate ACK event. In this case, the network is continuing to deliver segments from sender to receiver (as indicated by the receipt of duplicate ACKs). So TCP‚Äôs behavior to this type of loss event should be less drastic than with a timeout-indicated loss: TCP halves the value of cwnd (adding in 3 MSS for good measure to account for the triple duplicate ACKs received) and records the value of ssthresh to be half the value of cwnd when the triple duplicate ACKs were received. The fast-recovery state is then entered.Fast Recovery In fast recovery, the value of cwnd is increased by 1 MSS for every duplicate ACK received for the missing segment that caused TCP to enter the fast-recovery state. Eventually, when an ACK arrives for the missing segment, TCP enters the congestion-avoidance state after deflating cwnd. If a timeout event occurs, fast recovery transitions to the slow-start state after performing the same actions as inslow start and congestion avoidance: The value of cwnd is set to 1 MSS, and the value of ssthresh is set to half the value of cwnd when the loss event occurred. Fast recovery is a recommended, but not required, component of TCP. It is interesting that an early version of TCP, known as TCP Tahoe, unconditionally cut its congestion window to 1 MSS and entered the slow-start phase after either a timeout-indicated or triple-duplicate-ACK-indicated loss event. The newer version of TCP, TCP Reno, incorporated fast recovery. In this figure, the threshold is initially equal to 8 MSS. For the first eight transmission rounds, Tahoe and Reno take identical actions. The congestion window climbs exponentially fast during slow start and hits the threshold at the fourth round of transmission. The congestion window then climbs linearly until a triple duplicate ACK event occurs, just after transmission round 8. Note that the congestion window is 12 MSS when this loss event occurs. The value of ssthresh is then set to 0.5 * cwnd = 6 MSS. Under TCP Reno, the congestion window is set to cwnd = 6 MSS and then grows linearly. Under TCP Tahoe, the congestion window is set to 1 MSS and grows exponentially until it reaches the value of ssthresh, at which point it grows linearly.Other References https://blog.stackpath.com/glossary-cwnd-and-rwnd/" }, { "title": "Notes - The Network Layer", "url": "/C-Anirudh.github.io/posts/notes-the-network-layer/", "categories": "Academic Notes, Computer Networks", "tags": "ip, notes", "date": "2020-06-26 11:41:00 +0530", "snippet": " The following notes have been made with reference to the book Computer Networking A Top Down Approach by Kurose and Ross. Content has been quoted from the book. All credits to the author. The transport layer provides various forms of process-to-process communication by relying on the network layer‚Äôs host-to-host communication service. It does so without any knowledge about how the network layer actually implements this service. Unlike the transport and application layers, there is a piece of the network layer in each and every host and router in the network. An important distinction to keep in mind between the forwarding and routing functions of the network layer. Forwarding involves the transfer of a packet from an incoming link to an outgoing link within a single router. Routing involves all of a network‚Äôs routers, whose collective interactions via routing protocols determine the paths that packets take on their trips from source to destination node. Introduction Two hosts H1 &amp;amp; H2 and suppose H1 is sending information to H2. The network layer in H1 takes segments from the transport layer in H1, encapsulates each segment into a datagram (that is, a network-layer packet), and then sends the datagrams to its nearby router, R1. At the receiving host, H2, the network layer receives the datagrams from its nearby router R2, extracts the transport-layer segments, and delivers the segments up to the transport layer at H2. The primary role of the routers is to forward datagrams from input links to output links. Note: The routers in Figure 4.1 are shown with a truncated protocol stack, that is, with no upper layers above the network layer, because (except for control purposes) routers do not run application and transport-layer protocols. Forwarding and Routing The role of the network layer is thus deceptively simple‚Äîto move packets from a sending host to a receiving host. To do so, two important network-layer functions can be identified: Forwarding: When a packet arrives at a router‚Äôs input link, the router must move the packet to the appropriate output link. Routing: The network layer must determine the route or path taken by packets as they flow from a sender to a receiver. The algorithms that calculate these paths are referred to as routing algorithms. Every router has a forwarding table. A router forwards a packet by examining the value of a field in the arriving packet‚Äôs header, and then using this header value to index into the router‚Äôs forwarding table. The value stored in the forwarding table entry for that header indicates the router‚Äôs outgoing link interface to which that packet is to be forwarded. Depending on the network-layer protocol, the header value could be the destination address of the packet or an indication of the connection to which the packet belongs. The routing algorithm determines the values that are inserted into the routers‚Äô forwarding tables. The routing algorithm may be: Centralized (e.g., with an algorithm executing on a central site and downloading routing information to each of the routers) Decentralized (i.e., with a piece of the distributed routing algorithm running in each router) In either case, a router receives routing protocol messages, which are used to configure its forwarding table. Some other terms: Packet switch: a general packet-switching device that transfers a packet from input link interface to output link interface, according to the value in a field in the header of the packet. Some packet switches, called link-layer switches, base their forwarding decision on values in the fields of the link-layer frame; switches are thus referred to as link-layer (layer 2) devices. Other packet switches, called routers, base their forwarding decision on the value in the network-layer field. Routers are thus network-layer (layer 3) devices, but must also implement layer 2 protocols as well, since layer 3 devices require the services of layer 2 to implement their (layer 3) functionality. Other than forwarding and routing, in some computer networks there is a third important funtion called connection setup Some network layer architectures‚Äîfor example, ATM, frame relay, and MPLS ‚Äì‚Äìrequire the routers along the chosen path from source to destination to handshake with each other in order to set up state before network-layer data packets within a given source-to-destination connection can begin to flow. In the network layer, this process is referred to as connection setup. Virtual Circuit and Datagram Networks Like the transport layer, the network layer can provide connectionless service or connection service between two hosts. A network-layer connection service begins with handshaking between the source and destination hosts; and a network-layer connectionless service does not have any handshaking preliminaries. Although there are parallels with the transport layer connection-oriented and connectionless services, there are crucial differences: In network layer, services are host-to-host services provided by the network layer for the transport layer. In the transport layer the services are process-to-process services provided by the transport layer for the application layer. In all major computer network architectures to date (Internet, ATM, frame relay, and so on), the network layer provides either a host-to-host connectionless service or a host-to-host connection service, but not both. Computer networks that provide only a connection service at the network layer are called virtual-circuit (VC) networks; computer networks that provide only a connectionless service at the network layer are called datagram networks. The implementation of connection-oriented service in the transport layer and connection service in the network layer are different. Transport layer connection-oriented service is implemented at the edge of the network in the end systems; network layer connection service is implemented in the routers in the network core as well as in the end systems. Virtual-Circuit Networks While the Internet is a datagram network, many alternative network architectures including those of ATM and frame relay are virtual-circuit networks and, therefore, use connections at the network layer. These network-layer connections are called virtual circuits (VCs). A VC consists of: a path (that is, a series of links and routers) between the source and destination hosts VC numbers, one number for each link along the path entries in the forwarding table in each router along the path A packet belonging to a virtual circuit will carry a VC number in its header. Because a virtual circuit may have a different VC number on each link, each intervening router must replace the VC number of each traversing packet with a new VC number. The new VC number is obtained from the forwarding table. To illustrate the concept, consider the network shown in Figure 4.3. The numbers next to the links of R1 in Figure 4.3 are the link interface numbers. Suppose now that Host A requests that the network establish a VC between itself and Host B. Suppose also that the network chooses the path A-R1-R2-B and assigns VC numbers 12, 22, and 32 to the three links in this path for this virtual circuit. In this case, when a packet in this VC leaves Host A, the value in the VC number field in the packet header is 12; when it leaves R1, the value is 22; and when it leaves R2, the value is 32. For a VC network, each router‚Äôs forwarding table includes VC number translation; for example, the forwarding table in R1 might look something like this: Why have different VC number for each link along the path? First, replacing the number from link to link reduces the length of the VC field in the packet header. Second, and more importantly, VC setup is considerably simplified by permitting a different VC number at each link along the path of the VC. If a common VC number were required for all links along the path, the routers would have to exchange and process a substantial number of messages to agree on a common VC number (e.g., one that is not being used by any other existing VC at these routers) to be used for a connection. In a VC network, the network‚Äôs routers must maintain connection state information for the ongoing connections. Specifically, each time a new connection is established across a router, a new connection entry must be added to the router‚Äôs forwarding table; and each time a connection is released, an entry must be removed from the table. There are three identifiable phases in a virtual circuit: VC setup: During the setup phase, the sending transport layer contacts the network layer, specifies the receiver‚Äôs address, and waits for the network to set up the VC. The network layer determines the path between sender and receiver, that is, the series of links and routers through which all packets of the VC will travel. The network layer also determines the VC number for each link along the path. Finally, the network layer adds an entry in the forwarding table in each router along the path. During VC setup, the network layer may also reserve resources (for example, bandwidth) along the path of the VC. Data transfer: As shown in Figure 4.4, once the VC has been established, packets can begin to flow along the VC. VC teardown: This is initiated when the sender (or receiver) informs the network layer of its desire to terminate the VC. The network layer will then typically inform the end system on the other side of the network of the call termination and update the forwarding tables in each of the packet routers on the path to indicate that the VC no longer exists. The messages that the end systems send into the network to initiate or terminate a VC, and the messages passed between the routers to set up the VC (that is, to modify connection state in router tables) are known as signaling messages, and the protocols used to exchange these messages are often referred to as signaling protocols.Datagram Networks In a datagram network, each time an end system wants to send a packet, it stamps the packet with the address of the destination end system and then pops the packet into the network. As a packet is transmitted from source to destination, it passes through a series of routers. Each of these routers uses the packet‚Äôs destination address to forward the packet. Specifically, each router has a forwarding table that maps destination addresses to link interfaces; when a packet arrives at the router, the router uses the packet‚Äôs destination address to look up the appropriate output link interface in the forwarding table. The router then intentionally forwards the packet to that output link interface. To get some further insight into the lookup operation, let‚Äôs look at a specific example. Suppose that all destination addresses are 32 bits. A brute-force implementation of the forwarding table would have one entry for every possible destination address. Since there are more than 4 billion possible addresses, this option is totally out of the question. Now let‚Äôs further suppose that our router has four links, numbered 0 through 3, and that packets are to be forwarded to the link interfaces as follows: We could, for example, have the following forwarding table with just four entries: With this style of forwarding table, the router matches a prefix of the packet‚Äôs destination address with the entries in the table; if there‚Äôs a match, the router forwards the packet to a link associated with the match. When there are multiple matches, the router uses the longest prefix matching rule; that is, it finds the longest matching entry in the table and forwards the packet to the link interface associated with the longest prefix match. What‚Äôs inside a Router? A high-level view of a generic router architecture is shown in Figure 4.6. Four router components can be identified: Input ports: An input port performs several key functions. It performs the physical layer function of terminating an incoming physical link at a router An input port also performs link-layer functions needed to interoperate with the link layer at the other side of the incoming link Perhaps most crucially, the lookup function is also performed at the input port. It is here that the forwarding table is consulted to determine the router output port to which an arriving packet will be forwarded via the switching fabric. Control packets (for example, packets carrying routing protocol information) are forwarded from an input port to the routing processor. Note that the term port here refers to the physical input and output router interfaces Switching fabric The switching fabric connects the router‚Äôs input ports to its output ports. This switching fabric is completely contained within the router‚Äîa network inside of a network router! Output ports An output port stores packets received from the switching fabric and transmits these packets on the outgoing link by performing the necessary link-layer and physical-layer functions. Routing processor The routing processor executes the routing protocols, maintains routing tables and attached link state information, and computes the forwarding table for the router. It also performs some network management functions. A router‚Äôs input ports, output ports, and switching fabric together implement the forwarding function and are almost always implemented in hardware. These forwarding functions are sometimes collectively referred to as the router forwarding plane. The router control plane functions are usually implemented in software and execute on the routing processor (typically a traditional CPU).Input Processing A more detailed view of input processing is given in Figure 4.7. As discussed above, the input port‚Äôs line termination function and link-layer processing implement the physical and link layers for that individual input link. The lookup performed in the input port is central to the router‚Äôs operation‚Äîit is here that the router uses the forwarding table to look up the output port to which an arriving packet will be forwarded via the switching fabric. The forwarding table is computed and updated by the routing processor, with a shadow copy typically stored at each input port. The forwarding table is copied from the routing processor to the line cards over a separate bus (e.g., a PCI bus) indicated by the dashed line from the routing processor to the input line cards in Figure 4.6. With a shadow copy, forwarding decisions can be made locally, at each input port, without invoking the centralized routing processor on a per-packet basis and thus avoiding a centralized processing bottleneck. Given the existence of a forwarding table, lookup is conceptually simple‚Äîwe just search through the forwarding table looking for the longest prefix match, lookup must be performed in hardware for speed. Once a packet‚Äôs output port has been determined via the lookup, the packet can be sent into the switching fabric. In some designs, a packet may be temporarily blocked from entering the switching fabric if packets from other input ports are currently using the fabric. A blocked packet will be queued at the input port and then scheduled to cross the fabric at a later point in time. Although ‚Äúlookup‚Äù is arguably the most important action in input port processing, many other actions must be taken: physical and link-layer processing must occur, as discussed above the packet‚Äôs version number, checksum and time-to-live field must be checked and the latter two fields rewritten counters used for network management (such as the number of IP datagrams received) must be updated. Output processing Output port processing, shown in Figure 4.9, takes packets that have been stored in the output port‚Äôs memory and transmits them over the output link. This includes selecting and de-queueing packets for transmission, and performing the needed link-layer and physical-layer transmission functions.What is Head-of-the-Line (HOL) blocking Figure 4.11 shows an example in which two packets (darkly shaded) at the front of their input queues are destined for the same upper-right output port. Suppose that the switch fabric chooses to transfer the packet from the front of the upper-left queue. In this case, the darkly shaded packet in the lower-left queue must wait. But not only must this darkly shaded packet wait, so too must the lightly shaded packet that is queued behind that packet in the lower-left queue, even though there is no contention for the middle-right output port (the destination for the lightly shaded packet). This phenomenon is known as head-of-the-line (HOL) blocking in an input-queued switch.Reference videos for some topics Topic Video Link IP Datagram Format https://www.youtube.com/watch?v=AffMzrz96Nc IP Data Fragmentation and Re-Assembly https://www.youtube.com/watch?v=MmJonsmiwqc Introduction to Computer network and IP address https://www.youtube.com/watch?v=UXMIxCYZu8o Types of Casting: Unicast, Limited Broadcast, Directed Broadcast https://www.youtube.com/watch?v=hffYt7RDrgk&amp;amp;t=630s Subnets, Subnet Mask, Routing https://www.youtube.com/watch?v=3QWrq5gN8VY&amp;amp;t=209s Variable length subnet masking (VLSM) https://www.youtube.com/watch?v=GJrS5ckgjAs&amp;amp;t=622s Classless Inter Domain Routing (CIDR) https://www.youtube.com/watch?v=86RDE_bP1Bs&amp;amp;pbjreload=10 Subnetting in CIDR, VLSM in CIDR https://www.youtube.com/watch?v=zYOgpo0SDBc&amp;amp;pbjreload=10 Some interesting problems on subnet mask https://www.youtube.com/watch?v=O-8MYVVKpk8 Obtaining a Host Address: the Dynamic Host Configuration Protocol (DHCP) Once an organization has obtained a block of addresses, it can assign individual IP addresses to the host and router interfaces in its organization. A system administrator will typically manually configure the IP addresses into the router (often remotely, with a network management tool). Host addresses can also be configured manually, but more often this task is now done using the Dynamic Host Configuration Protocol (DHCP). DHCP allows a host to obtain (be allocated) an IP address automatically. A network administrator can configure DHCP so that a given host receives the same IP address each time it connects to the network, or a host may be assigned a temporary IP address that will be different each time the host connects to the network. In addition to host IP address assignment, DHCP also allows a host to learn additional information, such as its subnet mask, the address of its first-hop router (often called the default gateway), and the address of its local DNS server. Because of DHCP‚Äôs ability to automate the network-related aspects of connecting a host into a network, it is often referred to as a plug-and-play protocol. DHCP is a client-server protocol. A client is typically a newly arriving host wanting to obtain network configuration information, including an IP address for itself. In the simplest case, each subnet will have a DHCP server. If no server is present on the subnet, a DHCP relay agent (typically a router) that knows the address of a DHCP server for that network is needed. Figure 4.20 shows a DHCP server attached to subnet 223.1.2/24, with the router serving as the relay agent for arriving clients attached to subnets 223.1.1/24 and 223.1.3/24. In our discussion below, we‚Äôll assume that a DHCP server is available on the subnet. For a newly arriving host, the DHCP protocol is a four-step process. The four steps are: DHCP server discovery The first task of a newly arriving host is to find a DHCP server with which to interact. This is done using a DHCP discover message, which a client sends within a UDP packet to port 67. The UDP packet is encapsulated in an IP datagram. But to whom should this datagram be sent? The host doesn‚Äôt even know the IP address of the network to which it is attaching, much less the address of a DHCP server for this network. Given this, the DHCP client creates an IP datagram containing its DHCP discover message along with the broadcast destination IP address of 255.255.255.255 and a ‚Äúthis host‚Äù source IP address of 0.0.0.0. The DHCP client passes the IP datagram to the link layer, which then broadcasts this frame to all nodes attached to the subnet. An interesting read about the 0.0.0.0 IP address =&amp;gt; https://superuser.com/questions/949428/whats-the-difference-between-127-0-0-1-and-0-0-0-0 DHCP server offer(s) A DHCP server receiving a DHCP discover message responds to the client with a DHCP offer message that is broadcast to all nodes on the subnet, again using the IP broadcast address of 255.255.255.255. Since several DHCP servers can be present on the subnet, the client may find itself in the enviable position of being able to choose from among several offers. Each server offer message contains the transaction ID of the received discover message, the proposed IP address for the client, the network mask, and an IP address lease time‚Äîthe amount of time for which the IP address will be valid. It is common for the server to set the lease time to several hours or days. DHCP request The newly arriving client will choose from among one or more transmitsserver offers and respond to its selected offer with a DHCP request message, echoing back the configuration parameters. DHCP ACK The server responds to the DHCP request message with a DHCP ACK message, confirming the requested parameters. Once the client receives the DHCP ACK, the interaction is complete and the client can use the DHCP-allocated IP address for the lease duration. Since a client may want to use its address beyond the lease‚Äôs expiration, DHCP also provides amechanism that allows a client to renew its lease on an IP address. From a mobility aspect, however, DHCP does have shortcomings. Since a new IP address is obtained from DHCP each timea node connects to a new subnet, a TCP connection to a remote application cannot be maintained as a mobile node moves between subnets. Network Address Translation (NAT)Reference video - https://youtu.be/_MZbwHyE0CkRouting Algorithms Whether the network layer provides a datagram service (in which case different packets between a given source-destination pair may take different routes) or a VC service (in which case all packets between a given source and destination will take the same path), the network layer must nonetheless determine the path that packets take from senders to receivers. We‚Äôll see that the job of routing is to determine good paths (equivalently, routes), from senders to receivers, through the network of routers. Typically a host is attached directly to one router, the default router for the host (also called the first-hop router for the host). Whenever a host sends a packet, the packet is transferred to its default router. We refer to the default router of the source host as the source router and the default router of the destination host as thedestination router. The problem of routing a packet from source host to destination host clearly boils down to the problem of routing the packet from source router to destination router. A graph is used to formulate routing problems. Recall that a graph G = (N,E) is a set N of nodes and a collection E of edges, where each edge is a pair of nodes from N. In the context of network-layer routing, the nodes in the graph represent routers‚Äîthe points at which packet-forwarding decisions are made‚Äîand the edges connecting these nodes represent the physical links between these routers. Such a graph abstraction of a computer network is shown in Figure 4.27. An edge also has a value representing its cost. Typically, an edge‚Äôs cost may reflect the physical length of the corresponding link, the link speed, or the monetary cost associated with a link. Broadly, one way in which we can classify routing algorithms is according to whether they are global or decentralized. A global routing algorithm computes the least-cost path between a source and destination using complete, global knowledge about the network. That is, the algorithm takes the connectivity between all nodes and all link costs as inputs. This then requires that the algorithm somehow obtain this information before actually performing the calculation. The calculation itself can be run at one site (a centralized global routing algorithm) or replicated at multiple sites. In practice, algorithms with global state information are often referred to as link-state (LS) algorithms, since the algorithm must be aware of the cost of each link in the network. In a decentralized routing algorithm, the calculation of the least-cost path is carried out in an iterative, distributed manner. No node has complete information about the costs of all network links. Instead, each node begins with only the knowledge of the costs of its own directly attached links. Then, through an iterative process of calculation and exchange of information with its neighboring nodes (that is, nodes that are at the other end of links to which it itself is attached), a node gradually calculates the least-cost path to a destination or set of destinations. The decentralized routing algorithm we will see is called a distance-vector (DV) algorithm, because each node maintains a vector of estimates of the costs (distances) to all other nodes in the network. A second broad way to classify routing algorithms is according to whether they are static or dynamic. In static routing algorithms, routes change very slowly over time, often as a result of human intervention (for example, a human manually editing a router‚Äôs forwarding table). Dynamic routing algorithms change the routing paths as the network traffic loads or topology change. A dynamic algorithm can be run either periodically or in direct response to topology or link cost changes. While dynamic algorithms are more responsive to network changes, they are also more susceptible to problems such as routing loops and oscillation in routes. A third way to classify routing algorithms is according to whether they are load-sensitive or load-insensitive. In a load-sensitive algorithm, link costs vary dynamically to reflect the current level of congestion in the underlying link. If a high cost is associated with a link that is currently congested, a routing algorithm will tend to choose routes around such a congested link. Today‚Äôs Internet routing algorithms (such as RIP, OSPF, and BGP) are load-insensitive, as a link‚Äôs cost does not explicitly reflect its current (or recent past) level of congestion. The Link-State (LS) Routing Algorithm Recall that in a link-state algorithm, the network topology and all link costs are known, that is, available as input to the LS algorithm. In practice this is accomplished by having each node broadcast link-state packets to all other nodes in the network, with each link-state packet containing the identities and costs of its attached links. In practice this is often accomplished by a link-state broadcast algorithm. The link-state routing algorithm we present below is known as Dijkstra‚Äôs algorithm, named after its inventor. Dijkstra‚Äôs algorithm computes the least-cost path from one node to all other nodes in the network.The Distance-Vector (DV) Routing Algorithm Whereas the LS algorithm is an algorithm using global information, the distance-vector (DV) algorithm is iterative, asynchronous, and distributed. It is distributed in that each node receives some information from one or more of its directly attached neighbors, performs a calculation, and then distributes the results of its calculation back to its neighbors. It is iterative in that this process continues on until no more information is exchanged between neighbors (Interestingly, the algorithm is also self-terminating‚Äîthere is no signal that the computation should stop; it just stops). The algorithm is asynchronous in that it does not require all of the nodes to operate in lockstep with each other. Bellman-Ford is used to calculate the distances between the nodes. DV-like algorithms are used in many routing protocols in practice, including the Internet‚Äôs RIP and BGP, ISO IDRP, Novell IPX, and the original ARPAnet.A Comparison of LS and DV Routing Algorithms LS Routing Algorithm DV Routing Algorithm Each node talks with all other nodes (via broadcast), but it tells them only the costs of its directly connected links. Each node talks to only its directly connected neighbors, but it provides its neighbors with least-cost estimates from itself to all the nodes (that it knows about) in the network. Each node requires to know the cost of each link in the network. This requires O(N.E) messages to be sent. Also, whenever a link cost changes, the new link cost must be sent to all nodes. The DV algorithm requires message exchanges between directly connected neighbors at each iteration. The time needed for the algorithm to converge can depend on many factors. When link costs change, the DV algorithm will propagate the results of the changed link cost only if the new link cost results in a changed least-cost path for one of the nodes attached to that link. The implementation of LS is an O(N^2) algorithm requiring O(N.E)) messages. The DV algorithm can converge slowly and can have routing loops while the algorithm is converging. DV also suffers from the count-to-infinity problem. An LS node is computing only its own forwarding tables; other nodes are performing similar calculations for themselves. This means route calculations are somewhat separated under LS, providing a degree of robustness. An incorrect node calculation can be diffused through the entire network under DV. In the end, neither algorithm is an obvious winner over the other; indeed, both algorithms are used in the Internet." }, { "title": "Notes - Pretty Good Privacy (PGP)", "url": "/C-Anirudh.github.io/posts/notes-pretty-good-privacy/", "categories": "Academic Notes, Information Security", "tags": "pgp, s-mime, email-security, notes", "date": "2020-06-25 13:50:00 +0530", "snippet": " The following notes have been made with reference to the book Cryptography and Network Security: Principles and Practice, 5th Edition by William Stallings. Content has been quoted from the book. All credits to the author. With the increased reliance on email, there grows a demand for authentication and confidentiality services. Two such schemes that are used widely include: Pretty Good Privacy (PGP) and S/MIME.Pretty Good Privacy Created by Phil Zimmermann Provides confidentiality and authentication service that can be used for electronic mail and file storage applications Notations that will be used:Operational Description The actual operation of PGP consists of four services: authentication, confidentiality, compression, and e-mail compatibilityAuthenticationThis image illustrates the digital signature service provided by PGP. The sequence is as follows: The sender creates a message. SHA-1 is used to generate a 160-bit hash code of the message. The hash code is encrypted with RSA using the sender‚Äôs private key, and the result is prepended to the message. The receiver uses RSA with the sender‚Äôs public key to decrypt and recover the hash code. The receiver generates a new hash code for the message and compares it with the decrypted hash code. If the two match, the message is accepted as authentic. The combination of SHA-1 and RSA provides an effective digital signature scheme. Because of the strength of RSA, the recipient is assured that only the possessor of the matching private key can generate the signature. Because of thestrength of SHA-1, the recipient is assured that no one else could generate a new message that matches the hash code and, hence, the signature of the original message. As an alternative, signatures can be generated using DSS/SHA-1. Although signatures normally are found attached to the message or file that they sign, this is not always the case: Detached signatures are supported. A detached signature may be stored and transmitted separately from the message it signs.ConfidentialityThis image illustrates the confidentiality service provided by PGP. The sequence is as follows: The sender generates a message and a random 128-bit number to be used as a session key for this message only (one time key). The message is encrypted using CAST-128 (or IDEA or 3DES) with the session key. The session key is encrypted with RSA using the recipient‚Äôs public key and is prepended to the message. The receiver uses RSA with its private key to decrypt and recover the session key. The session key is used to decrypt the message. As always, one must address the problem of key distribution. In PGP, each symmetric key is used only once. That is, a new key is generated as a random 128-bit number for each message. Thus, although this is referred to in the documentation as a session key, it is in reality a one-time key. Because it is to be used only once, the session key is bound to the message and transmitted with it. To protect the key, it is encrypted with the receiver‚Äôs public key.Confidentiality and AuthenticationThis image illustrates how both service can be used for the same message. First, a signature is generated for the plaintext message and prepended to the message. Then the plaintext message plus signature is encrypted using CAST-128 (or IDEA or 3DES), and the session key is encrypted using RSA (or ElGamal). In summary, when both services are used, the sender first signs the message with its own private key, then encrypts the message with a session key, and finally encrypts the session key with the recipient‚Äôs public key. Compression As a default, PGP compresses the message after applying the signature but before encryption. This has the benefit of saving space both for e-mail transmission and for file storage. The placement of the compression algorithm, indicated by Z for compression and Z^‚Äì1 for decompression in the above Figures, is critical. The signature is generated before compression for two reasons: It is preferable to sign an uncompressed message so that one can store only the uncompressed message together with the signature for future verification.If one signed a compressed document, then it would be necessary either to store a compressed version of the message for later verification or to recompress the message when verification is required. Even if one were willing to generate dynamically a recompressed message for verification, PGP‚Äôs compression algorithm presents a difficulty. The algorithm is not deterministic; various implementations of the algorithm achieve different tradeoffs in running speed versus compression ratio and, as a result, produce different compressed forms. However, these different compression algorithms are interoperable because any version of the algorithm can correctly decompress the output of any other version. Applying the hash function and signature after compression would constrain all PGP implementations to the same version of the compression algorithm. Message encryption is applied after compression to strengthen cryptographic security. Because the compressed message has less redundancy than the original plaintext, cryptanalysis is more difficult. The compression algorithm used is ZIP.E-mail Compatibility Many electronic mail systems only permit the use of blocks consisting of ASCII text. To accommodate this restriction, PGP provides the service of converting the raw 8-bit binary stream to a stream of printable ASCII characters. The scheme used for this purpose is radix-64 conversion. Each group of three octets of binary data is mapped into four ASCII characters. This format also appends a CRC to detect transmission errors. One noteworthy aspect of the radix-64 algorithm is that it blindly converts the input stream to radix-64 format regardless of content, even if the input happens to be ASCII text.Summary of PGP Services" }, { "title": "TJCTF - Circus challenge writeup", "url": "/C-Anirudh.github.io/posts/tjctf-circus-writeup/", "categories": "Technical, CTF-writeups", "tags": "ctf, writeups, git-security, php-type-juggling, magic-hashes", "date": "2020-05-27 17:30:00 +0530", "snippet": "This is a writeup for the Circus challenge in the recently held TJCTF 2020.After staring at the website for some time and going through its source code, I didn‚Äôt find anything of significance. So I decided to use the dirsearch command line tool to look for files and directories in the website.$ python dirsearch.py -b -u https://circus.tjctf.org/ -e *The tool gave me some interesting results -As you can see from the image, the website had hosted its version control repository (.git/) in production. This is bad and can be used to gain access to the website‚Äôs source code.Please refer this post for more detailed information on this.Heading to https://circus.tjctf.org/.git/refs/heads/master gave us the commit hash 4879af041fba89b387e751a94bfe5dbee4bd7528.We use this to download the commit-object from the server by going to https://circus.tjctf.org/.git/objects/48/79af041fba89b387e751a94bfe5dbee4bd7528I then created a local git repository and pasted the commit-object file in the .git/objects/48 folder. Note: Here 48 is the first 2 bytes of the commit hash$ mkdir cirucs$ cd circus/$ git init$ mkdir .git/objects/48/$ cp ~/Downloads/79af041fba89b387e751a94bfe5dbee4bd7528 ~/Downloads/circus/.git/objects/48/Now we can analyse it further:This tells us that the downloaded object is a commit:$ git cat-file -t 4879af041fba89b387e751a94bfe5dbee4bd7528commitGetting further details:$ git cat-file -p 4879af041fba89b387e751a94bfe5dbee4bd7528tree 2f16dc45649e2748d2345f01b076fb6efae38f47parent e2731f0ea54feb0a892fd5377a932053bb3baf61author kfb &amp;lt;kfb@circus.tjctf.org&amp;gt; 1584979440 -0700committer kfb &amp;lt;kfb@circus.tjctf.org&amp;gt; 1584979440 -0700oopsWe next download the tree object and analyse it in the same way. Go to https://circus.tjctf.org/.git/objects/2f/16dc45649e2748d2345f01b076fb6efae38f47 to download the object and paste it in the circus/.git/objects/2f/ folder.Analysing the tree object:$ git cat-file -p 2f16dc45649e2748d2345f01b076fb6efae38f47100644 blob 0c2dcae6b4a2df8b0e36f9764c82e67f63b6ffa5 .gitignore040000 tree efb43702c73bf9b9ed4bdc67ab139e8431fff12e css040000 tree af6d89e6ba71c3d121bb931e11d2d0ca52f4bcb3 img100644 blob ad9052a7a90a878dcbb120089eb96739149511ac index.php040000 tree 4604bf31e608e07a063c11888dc3092cf77ccfff js040000 tree 8a0a57c3988c44b23e079e4cccf603bc58d911b8 lib100644 blob ef808b5889ece41f90c38567d53b7e8e13c0a489 logout.phpWe now download the index.php blob (follow the same step as above) and cat its contents.We extract the following PHP code from the file:&amp;lt;?php require __DIR__ . &quot;/../include/flag.php&quot;; session_start(); $error = &quot;&quot;; mysqli_report(MYSQLI_REPORT_ERROR | MYSQLI_REPORT_STRICT); if (isset($_POST[&quot;username&quot;]) &amp;amp;&amp;amp; isset($_POST[&quot;password&quot;])) { try { $mysqli = new mysqli(NULL, NULL, NULL, &quot;circus&quot;); $stmt = $mysqli-&amp;gt;prepare(&quot;SELECT * FROM users WHERE username = ?&quot;); $stmt-&amp;gt;bind_param(&quot;s&quot;, $_POST[&quot;username&quot;]); $stmt-&amp;gt;execute(); $res = $stmt-&amp;gt;get_result(); if ($res-&amp;gt;num_rows === 0) { $error = &quot;Invalid credentials&quot;; } else { $row = $res-&amp;gt;fetch_assoc(); if (hash(&#39;sha256&#39;, $_POST[&quot;password&quot;]) == $row[&quot;password&quot;]) { $_SESSION[&quot;id&quot;] = $row[&quot;id&quot;]; $_SESSION[&quot;name&quot;] = $row[&quot;fname&quot;]; } } } catch (Exception $e) { $error = &quot;Error signing in&quot;; } }?&amp;gt;From https://circus.tjctf.org/.git/logs/refs/heads/master we can see that the commit hash we analysed was the second commit. The commit message ‚Äúoops‚Äù also hints that the developer might have pushed some sensitive content in his first commit which he corrected in the second commit. But the sensitive content will still be stored in the git version history.Read this blog post for more.We saw that the second commit contained a new .gitignore file. So lets print the contents of that.$ git cat-file -p 0c2dcae6b4a2df8b0e36f9764c82e67f63b6ffa5backup.shbackupsWe can see that the developer must have committed the backup.sh file before (1st commit) which he has now put in the .gitnore file now.Going to https://circus.tjctf.org/backup.sh , we are pointed to https://circus.tjctf.org/backups/users.sql which gives us the backup of the database containing usernames and their password hashes.The password verification logic in the PHP code uses the ‚Äú==‚Äù operator and we have the SHA-256 password hashes of the users, so it was safe to assume that the website may be susceptible to Type Juggling attack through magic hash comparison.Refer this blog post for more about magic hashes.I searched the SQL file for a password hash which fit the magic hash format of 0+e[0-9]+ and was able to find a user who fit the bill:(773,&#39;Andon1956&#39;,&#39;0e75759761935916943951971647195794671357976597614357959761597165&#39;,&#39;Rosie&#39;,&#39;Kelly&#39;)All that I had to do now, was use the username Andon1956 along with a matching SHA-256 magic hash.This GitHub repository holds a list of SHA-256 magic hashes.The flag was displayed on screen after logging in.I would like to thank Nimisha Dughyala for guiding me in solving this challenge. It wouldn‚Äôt have been possible without her :)" }, { "title": "TJCTF - Gamer W challenge writeup", "url": "/C-Anirudh.github.io/posts/tjctf-gamerw-writeup/", "categories": "Technical, CTF-writeups", "tags": "ctf, writeups, wasm-game, cetus-extension", "date": "2020-05-27 11:41:00 +0530", "snippet": "This is a writeup for the Gamer W challenge in the recently held TJCTF 2020.The challenge required us to cheat in a web assembly game using the Cetus browser extension.I cloned the extension repository from GitHub and loaded it in chrome using developer mode. Note: Instructions to setup the extension in either Chrome or Firefox can be found in its GitHub README or Wiki.As soon as we enter the game, we are given instructions on how to move our character (W, A, S&amp;amp; D) and attack (X&amp;amp;C). We are also provided with a shop on the home screen which allows us to upgrade the traits of our character in exchange for gold coins.I went ahead and played the game without thinking of how to cheat. I killed 4 skulled goons and then the main boss appeared. He was impossible to kill, as he spread out his attacks (impossible to dodge) and I was dead before long.So, now I had to find a way to cheat and defeat the final boss.By looking at the game, we can figure out that there are two main variables which we can modify to cheat: The Health variable The Gold Coins variableUsing Cetus‚Äôs search feature, I searched for the addresses storing the values of health and gold coins.I froze the value in the address storing the health and gave myself a whole lot of gold coins by changing the value in the address holding the amount of gold coins. Now that I was wealthy and invincible üòà, I maxed out my character from the store and went to face the boss again.However, as I was getting close to killing him, the boss drank something (a potion), which gave him regenerative health. If I was somehow able to give him a hit before the potion took its effect, he teleported and put me behind a barricade, making it impossible for me to reach him.This is the place where I was stuck for a long time, I understood that I had to do two things: Be able to kill the boss even with his regenerative potion Kill him before he teleports out of my reachI tried a few things like checking whether there was a way to change the position coordinates of my character, getting hold of the address that stored the health of the boss, using the speed hack in Cetus to attack quickly, etc. None of them worked out, so I started looking for other things I could manipulate.I looked at the items in the store again and realized that if I could change the swing damage from my weapon to a very high value, I could kill the boss quickly even with his regenerative powers! Using Cetus‚Äô search feature again, I got hold of the address storing my weapon‚Äôs swing damage value and increased it. Note: The value of swing damage resets if we enter the shop. So after manually changing its value through Cetus, don‚Äôt enter the shop.Now when I went and faced the boss, I could kill him and the game ended.I was presented with the flag for the challenge at the end screen." }, { "title": "Aptitude Topic - Calendars", "url": "/C-Anirudh.github.io/posts/aptitude-topic-calendars/", "categories": "Academic Notes, Aptitude & Reasoning", "tags": "aptitude, calendar", "date": "2019-08-07 21:41:00 +0530", "snippet": "Years can be classified into two types, a leap year and a non-leap year. A leap year has 366 days while a non-leap year has 365 days.For an year to be a leap year, it must be divisible by 4 but for centuries, it must also bedivisible by 400. So the years 1700 and 2200 are not leap years as they are not divisible by 400.Odd daysIt is the number of days left after a week, i.e., the remainder we get when we divide a given number of days by 7. For example, in 72 days we have 2 odd days. Odd day Associated day of the week 0 Sunday 1 Monday 2 Tuesday 3 Wednesday 4 Thursday 5 Friday 6 Saturday A leap year has 2 odd days ( 366 % 7 ) while a non-leap year has 1 odd day. Number of years Total number of odd days 100 5 200 3 300 1 400 0 What was the day of the week on 21st June, 2019? The steps we must follow are: Write the closest leap year which is a multiple of 400 as it will have 0 odd days Find the odd days for the rest of the years (taking into consideration the leap years) and the months. Check the day of the week corresponding to the final number of odd days we got. 21June2019 = 2000years + 18years + Jan + Feb + Mar + Apr + May + 21daysofJuneoddDays = 0 + 22 + 3 + 0 + 3 + 2 + 3 + 0 = 33 If we divide by 7 again, we get the final odd days left asoddDays = 5Explanation-----------2000 years have 0 odd days. Then, till 2019 , 18 years have gone by which contribute 22 odddays (4 leap years + 14 non-leap years). January , March and May give 3 odd days ( 31 % 7 )and April gives 2 odd days ( 30 % 7 ). As 2019 is non-leap, February gives 0 odd days( 28 % 7). As for the 21 days in June, they too give 0 odd days. As the number of odd dayswe got is 5, the 21st day of June will be a Friday.Dooms Day methodThis is a method to find the day of the week of a particular date.Last day of February = 4th day of April = 6th day of June = 8th day of August = 10th day of October = 12th day of DecemberYou can remember this as:Last day of February = 4/4 = 6/6 = 8/8 = 10/10 =12/12Where the numerator refers to the day and the denominator to the month.The last day of February is called Dooms Day and can be calculated according to the equation given below:Doomsday = Anchorday + (YY/12) + R(YY/12) + [R(YY/12)]/4 Range of years Number of Anchor days 1800 - 1899 5 1900 - 1999 3 2000 - 2099 2 2100 - 2199 0 YY are the last two digits of the year for which we are finding and R is the reminder we get when we divide YY by 12.What was the day of the week on 28th June, 2019?Doomsday = 2 + 19/12 + [R.(19/12)] + [R.(19/12)]/4Doomsday=2+1+7+1=11Here the year is 2019, so the Anchor day will be 2 and YY will be 19. The value of R willbe 19%12 which is equal to 7.We take only the integer values from the division.Now we got 11 days which has 4 odd days (11 % 7), the 4th odd day is a Thursday. Hence, the last day of February in 2019 was a Thursday. This implies that the 6th day of June is a Thursday, so is the 13th, 20th and 27th day of June. Thus June 28 will be a Friday.Different type of question: In what future year can we reuse the calendar of 2007 ?Jan 1st 2007 --&amp;gt; Monday 2008 --&amp;gt; Tuesday 2009 --&amp;gt; Thursday (As 2008 is leap year and gives 2 odd days) 2010 --&amp;gt; Friday 2011 --&amp;gt; Saturday 2012 --&amp;gt; Sunday 2013 --&amp;gt; Tuesday (As 2012 is a leap year) 2014 --&amp;gt; Wednesday 2015 --&amp;gt; Thursday 2016 --&amp;gt; Friday 2017 --&amp;gt; Sunday (As 2016 is a leap year) 2018 --&amp;gt; MondaySo 2007 ‚Äòs calendar can be reused in 2018.In questions such as above we can only match a leap year with another leap year and a non-leap year with another non-leap year, i.e, if we started with a leap year, we must end at a leap year and NOT at a non-leap which has same week day." }, { "title": "First Go program", "url": "/C-Anirudh.github.io/posts/first-go-program/", "categories": "Technical, Tutorial", "tags": "go", "date": "2019-07-08 19:12:00 +0530", "snippet": "Every Go source file belongs to a package. A package is nothing but a collection of files. Here by defining the package as main, we are telling the Go compiler to compile the package as an executable file and not as a shared library. When you compile a file in main package, Go gives us a binary file which when executed calls the main function (the starting point of our program).The import statement is used to import the standard libraries which we download when we install Go. The standard libraries were provided by the developers of Go to make our lives easier and contain commonly used functions. If you have used other programming languages like C or Java, this will not be alien to you.In the main function, we call the Println function defined in the fmt package to print our output to the console. fmt has many functions to display output and each of them have their own use case.That‚Äôs it ! You have just written your first program in Go.package mainimport ( &quot;fmt&quot;)func main() { fmt.Println(&quot;My first Go program.&quot;)}" }, { "title": "Dignity of Labour", "url": "/C-Anirudh.github.io/posts/dignity-of-labour/", "categories": "Opinion", "tags": "opinion", "date": "2019-07-04 17:19:00 +0530", "snippet": "Dignity of labour refers to the philosophy that every occupation is important and deserves the same respect as any other, i.e, no job should be considered inferior. All labour that uplifts humanity has dignity and importance and should be undertaken with painstaking excellence. Martin Luther kingLet me tell you a story about the time when I first came to understand the dignity of labour. I was in grade III and part of a class of fifty. We were a mischievous bunch and wrecked havoc in the absence of a teacher. It was during this time that we had discovered the fun activity of throwing water from our water bottles at each other. Needless to say, this left the class wet and messy. Our science teacher, distraught at our behaviour asked us, who was going to clean the mess? The first word that came to our mouth was Didi (which means elder sister in Hindi). At the time, our school employed 12-15 women from a near-by village as janitors. They swept and wiped the floors, ran messages from the administration and performed other odd jobs. They were the people that students called for when someone had been sick or had spilt something. The solution to every non-academic problem was Didi. The teacher however didn&#39;t fancy the solution we had offered and decided to teach us two valuable life lessons. One being that in life you had to clean up your own mess, she ( the science teacher) made us clean the water ourselves and the second one was about the dignity of labour.In school we had a ritual where we stood whenever a teacher entered the class and greeted him/her with a good morning or good afternoon. This was done as a mark of respect for the teacher. However, we didn&#39;t follow this ritual when a didi entered the class for in our minds, she was just a cleaner and unimportant, plus we hadn&#39;t been specifically asked to do so. All this changed that day, the science teacher taught us to value her role in the school and instructed us to stand and wish whenever a didi entered the class. We were a little shocked but went through with it. Till this day, I remember the look of surprise that a didi had when she entered the class and fifty odd students rose and chimed &quot;good morning didi&quot;. We enjoyed the look of surprise on their faces and it became a part of our ritual. Looking back, I realise the positive effect that it had on me and how it changed me for the better. This incident coupled with the fact that our school felicitated and recognized all staff (on stage) on Labourers Day (May 1st) gave me strong faith in the dignity of labour. The dignity of labour depends not on what you do, but how you do it. Edwin Osgood GroverThe society is like a well oiled machine and each one of us is a cog, remove one and chaos ensues. Every occupation has its own requirements and are classified mainly into two categories, physical labour (jobs which require more brawn) and mental labour (jobs which require more brains). However, the world today has grown to detest physical labour. While we can hear children of an engineer or a doctor say that they want to become like their parents, rarely do we hear a farmer&#39;s child say he wants to be a farmer or a plumber&#39;s wanting to be a plumber. This is because the farmers or plumbers don&#39;t respect the occupation themselves and don&#39;t want their children following their footsteps. They consider the job they do to be inferior to the one&#39;s that require mental labour. The world, according to them is run by people wearing suits sitting in air conditioned offices. We can&#39;t blame them either for thinking this way, jobs involving physical labour pays much less and is not as respected as jobs that involve mental labour. Though this is a sad state of affairs it doesn&#39;t look like it will change anytime soon. People need to realise that each and every job is important. As Shakespeare would say, the world is a stage and each of us has a role to play. The world cannot be run by Doctors or engineers alone.I will end here with one of my favourite quotes. If a man is called to be a street sweeper. He should sweep streets even as a Michelangelo painted , or Beethovencomposed music or Shakespeare wrote poetry. He should sweep streets so well that all hosts of heaven and earth pause tosay; ‚ÄúHere lives a great sweeper who did his job well‚Äù Martin Luther King Jr." } ]
